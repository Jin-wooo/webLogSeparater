{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parsing(path):#파싱을 진행하는 함수\n",
    "    with open(path,'r',encoding='utf-8') as f:#파일을 읽어드리고 ['로그','로그',...] 이런식으로 로그를 구조화\n",
    "        train=[]\n",
    "        para=\"\"\n",
    "        while True:\n",
    "            l = f.readline() #한줄씩 읽어 옵니다\n",
    "    \n",
    "            if not l:\n",
    "                break #파일을 전부 읽으면 읽기를 중단합니다.\n",
    "\n",
    "            if l != \"\\n\":\n",
    "                para +=l\n",
    "\n",
    "            while l != \"\\n\":\n",
    "                l = f.readline()\n",
    "\n",
    "            if para!='':\n",
    "                if para[:4]=='POST' or para[:3] == 'PUT': \n",
    "                    para+=f.readline()\n",
    "                train.append(para)\n",
    "                para=\"\"\n",
    "\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(path,mod='train'): #데이터셋을 생성합니다. 파싱한 데이터와 라벨을 생성합니다 \n",
    "    x = parsing(f'{path}norm_{mod}.txt') # mod에 따라 train을 가져올지 test 데이터를 가져올지 결정됩니다.\n",
    "    y = [0]*len(x) # 정상 라벨 0 을 정상 데이터 개수 만큼 생성\n",
    "    x += parsing(f'{path}anomal_{mod}.txt')\n",
    "    y += [1]*(len(x)-len(y)) # 비정상 라벨 1을 비정상 데이터 개수 만큼 생성\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(train_x,test_x): #문장을 벡터로 만듭니다 해당 코드에서는 기본적인 tf idf를 사용하고 있습니다.\n",
    "    tf = TfidfVectorizer(analyzer=\"char\", ngram_range = (3,3))\n",
    "    tf = tf.fit(train_x)\n",
    "    train_vec = tf.transform(train_x)\n",
    "    test_vec = tf.transform(test_x)\n",
    "    return train_vec,test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_vec,train_y): #랜덤 포레스트로 훈련 시킵니다. 모델을 바꾸고 싶다면 이 함수를 변경해야 합니다.\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(train_vec,train_y)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_y,test_vec,rf): #입렵 받은 테스트와 모델로 테스트를 실시합니다\n",
    "    pred = rf.predict(test_vec)\n",
    "    print(accuracy_score(test_y,pred))\n",
    "    print(f1_score(test_y,pred))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### 실행 코드 #######################\n",
    "################################################\n",
    "train_x, train_y = dataset('./','train')\n",
    "test_x, test_y =  dataset('./','test')\n",
    "\n",
    "train_vec, test_vec = vectorize(train_x, test_x)\n",
    "rf = train(train_vec, train_y)\n",
    "pred = test(test_y,test_vec, rf)\n",
    "\n",
    "########################################################\n",
    "tf = TfidfVectorizer()\n",
    "tf = tf.fit(train_x)\n",
    "\n",
    "# print(len(tf.vocabulary_)) # 고유한 단어가 대략 8만개가 나옵니다\n",
    "\n",
    "# print(tf.transform(train_x)[0]) #로그 하나당 약 8만차원이 나옵니다\n",
    "                            # 필요없는 문장 때문에 단어의 개수가 많이 진것일  수도 있으니 데이터를 분석하여 필요한 부분만 사용하는것이 좋습니다\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c823e32c24d06b3518059b5f5e11ccae729689482027ea5186dc849db7650ef7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
